# -*- coding: utf-8 -*-
"""nyc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bzRvLv7XFzEBIRR2LbhEHJcMLmvGo4K4
"""

!pip install pandas matplotlib plotly scikit-learn spacy --quiet
!python -m spacy download en_core_web_sm

import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import spacy
from google.colab import files

df = pd.read_csv('Data.csv')
df.head()

df = df[[
    "Created Date", "Closed Date", "Complaint Type", "Descriptor",
    "Location Type", "Incident Zip", "City", "Borough",
    "Latitude", "Longitude", "Status", "Agency"
]]

df.dropna(subset=["Complaint Type", "Borough", "Latitude", "Longitude"], inplace=True)

df["Created Date"] = pd.to_datetime(df["Created Date"], errors="coerce")
df["Closed Date"] = pd.to_datetime(df["Closed Date"], errors="coerce")

df.reset_index(drop=True, inplace=True)

print("Shape of cleaned data:", df.shape)
print("Top complaint types:\n", df["Complaint Type"].value_counts().head(10))
print("\nTop boroughs:\n", df["Borough"].value_counts())

df.to_csv("cleaned_data.csv", index=False)
files.download("cleaned_data.csv")

df["text"] = df["Complaint Type"].astype(str) + " " + df["Descriptor"].astype(str)

df[["Complaint Type", "Descriptor", "text"]].head()

category_map = {
    "Noise - Street/Sidewalk": "Noise",
    "Noise - Commercial": "Noise",
    "Noise - Residential": "Noise",
    "Noise": "Noise",
    "Loud Music/Party": "Noise",
    "HEAT/HOT WATER": "Sanitation",
    "Water System": "Water",
    "Plumbing": "Water",
    "Dirty Conditions": "Sanitation",
    "Rodent": "Sanitation",
    "Street Condition": "Road",
    "Broken Muni Meter": "Road",
    "Illegal Parking": "Transport",
    "Abandoned Vehicle": "Transport",
}

df["label"] = df["Complaint Type"].map(category_map)

df.dropna(subset=["label"], inplace=True)

df["label"].value_counts()

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(
    df["text"], df["label"], test_size=0.2, random_state=42, stratify=df["label"]
)

tfidf = TfidfVectorizer(stop_words="english", max_features=5000)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

y_pred = model.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))

import plotly.express as px

# Step 1: Get counts and rename columns
category_counts = df["label"].value_counts().reset_index()
category_counts.columns = ["Category", "Count"]

# Step 2: Plot
fig = px.bar(
    category_counts,
    x="Category", y="Count",
    title="Top Complaint Categories",
    text="Count"
)
fig.show()

fig = px.pie(
    df,
    names="Borough",
    title="Complaint Distribution by Borough"
)
fig.show()

fig = px.scatter_mapbox(
    df.sample(1000),  # limit for performance
    lat="Latitude", lon="Longitude",
    color="label",
    hover_data=["Complaint Type", "Descriptor", "Borough"],
    zoom=10,
    mapbox_style="carto-positron",
    title="Geographic Distribution of Complaints"
)
fig.show()